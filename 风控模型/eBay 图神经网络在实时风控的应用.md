# eBay 图神经网络在实时风控的应用

 ebay - 韩志超 - 2022-02-15

https://mp.weixin.qq.com/s/d2IxXIrRKXB6-iqK-lue4g

**导读：**本文主要介绍图神经网络在支付风控方面一些实时场景的应用，侧重于**数据层面的点边构建**的实践，以及在模型架构层面的技巧。模型上完全采用图算子来构建时空概念，可以复用到大部分的风控领域，或者是**有一定时间间隔的决策场景**，并且在图领域的所有比较新的进展都可以嵌到框架中，包括图结构的预训练，新的网络结构，以及在**部署层面大规模图切割**的方案。

今天的分享包括以下几大部分：

- 电商支付中的反欺诈场景
- 实时图实验构图的挑战
- 现阶段可行的端到端方案
- 工作小结和对未来的展望

## 1. eBay支付风险场景 - 反欺诈场景

### 1.1 交易流程中的风险评估

- 用户在eBay上**完成注册，一直到购买商品**，这些行为背后都会涉及到非常多的**风险评估点**，从发生的时间顺序来看，可以分为**交易前，交易中和交易后**
  - **交易前**是指，用户注册时是不是存在着**大规模集中注册**的嫌疑，或者**用户登录**时是不是有可能是一个**被盗号的状态**；
  - 当交易发生的时候，会连同**支付网关和卡组织**一起来核验信息，检查用户使用的**支付手段**是否存在**被盗用**的可能；
  - 在完成交易后，会连同它的**买家卖家数据链路**来看是不是存在**洗钱或者刷单**的共谋行为。
- 虽然集中注册和后处理方面，也就是交易后的这些**账号层面的排查，图关联**确实能够起到显著的作用，但是在电商领域，对于**==支付风险实时的防范==**才是我们业务方最为关注的。毕竟在*用户刚刚注册时，能够采集到的信息相对有限，而在后处理阶段，损失已经切切实实地造成*了。那么我们这次的分享的重点，就会集中在**实时的异常风险检测**方面。
- ![图片](eBay%20%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9C%A8%E5%AE%9E%E6%97%B6%E9%A3%8E%E6%8E%A7%E7%9A%84%E5%BA%94%E7%94%A8.assets/640-16449976922632.webp)

### 1.2  传统模型的端到端流程

![图片](eBay%20%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9C%A8%E5%AE%9E%E6%97%B6%E9%A3%8E%E6%8E%A7%E7%9A%84%E5%BA%94%E7%94%A8.assets/640-16449980781873-16449980796485.webp)

- 为了实时高效地进行交易风险评估，ebay有着**端到端取数算数决策**，执行的系统链路能够有效地整合**交易数据**，**行为数据**以及**第三方的信息**作为决策的依据

##### 传统的监督模型端到端的流程: 以买家盗号风险为例

- （盗号是指欺诈分子通过撞库，钓鱼或者是暗网渠道采购等方式获得了用户的正常的登录信息，利用账号绑定的支付卡进行交易的行为。）

  ![图片](eBay%20%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9C%A8%E5%AE%9E%E6%97%B6%E9%A3%8E%E6%8E%A7%E7%9A%84%E5%BA%94%E7%94%A8.assets/640-16449984049376-16449984064578.webp)

- 首先是根据盗号的场景特点，来定义和提取有效的变量作为特征；

- 然后根据用户的回报退款记录来作为训练标签，以未经授权的交易作为盗号的标签。由于好坏样本在欺诈场景里是极度不均匀的，我们需要对这数据进行重采样；

- 通常是使用GBDT模型，比如lightGBM来进行训练；

- 最后我们把训练的好的模型部署到平台上，对交易风险进行实时的评估和决策。

#### 1.3 传统模型的不足 - 无法捕捉关联关系特征

- ![图片](eBay%20%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9C%A8%E5%AE%9E%E6%97%B6%E9%A3%8E%E6%8E%A7%E7%9A%84%E5%BA%94%E7%94%A8.assets/640-16449985609809-164499856348011.webp)
  - 从上图中的三笔交易可以看到，**有部分的关联实体是被共享**的，比如说交易的邮寄地址，交易的是支付手段，以及记账的邮箱，**==这一类关联关系特征也被叫做图变量==**，从评估的指标上是非常有效的特征。
  - 如果我们想把**关联关系这个方案也整合进来**的话，需要进一步的人工来参与，但相对于图卷积得到的特征表达，人设计的迭代过程毕竟是比较复杂的。就像CV领域里面视觉算子特征，像SIFT，HoG，之于CNN卷积层发展关系，可能五年后，十年后我们再来回过头来看欺诈场景这些特征设计，尤其是在关联关系上的设计，GNN是有着不可比拟的优势的。

## 2. 实时图挑战

- 为什么到现在我们在实时欺诈场景里面GNN的部署还是有点困难

### 2.0 构图(图定义)

- 采用**二部图**的形式，图的左边可以看到(节点)定义以**事件**为主，比如交易的订单；图的右边是订单**关联到的实体**，比如寄送地址，联系电话。
- 同时我们构图是**异构图**，不是同构图
  - 因为同构图会产生大量的冗余边，
  - 而且二部图在视觉化上也优于同质图。
  - 同时也因为事件节点都对应到订单上，使用二部图能够在日志中比较好的*还原出这些订单在线上传统模型的特征*，用于图实验的开展。
- <img src="eBay%20%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9C%A8%E5%AE%9E%E6%97%B6%E9%A3%8E%E6%8E%A7%E7%9A%84%E5%BA%94%E7%94%A8.assets/640-164499874947214.webp" alt="图片" style="zoom: 50%;" />

### 2.1 实时图实验构图的时效 - 时间跨越问题 - 有向图

- 问题： 这样一个简单的二部图的构造，会涉及**多个时间点**，比如说绿色的两个订单是在9月1号发生的，红色的订单是在9月5号发生的，所以右边的红色地址同时关联了两天的订单，那么会带来一个问题，如果以这张图去构图做消息传递的话，那么9月5号的订单信息也会传给这个地址，然后再传到9月1号的订单。这样传递的过程中就出现了**==时间跨越==**的问题，会使得模型在训练的时候具备了推断时不可能有的预测力，我们首先就要解决**构图的有效性**。

- 为了让时间不穿越，比较自然的一个方案是**一个时间切片构一张图**，但这样会导致实验阶段有**大量的冗余图存储**
- 比较理想的方案是**只构建一张图让它跨越各个时间切片**，通过**==有向图的形式来隔绝未来信息==**。

### 2.2 在线推断的延迟

#### **图查询延时**

- 在邻居查询时，由于涉及到转运仓或者是一些公共IP，很容易有**超过百万的关联群组**。而通常未经调优的包括关联关系也好，还有系统层面的优化也好，如果直接拿来用在超大群组上面查询，不可避免地会产生**近百毫秒的延时**，而这对于实时场景线上是根本无法接受的；

#### **关联特征拼接**

- 观察可以发现**同一个订单能够关联到数百个节点**，这样导致**对应节点的特征获取**也会是一个大问题；

#### DNN在线推断耗时  

- 深度模型推断本身也会比传统的模型要耗费时间。

### 2.3 效果对比： GBDT

- ![图片](eBay%20%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9C%A8%E5%AE%9E%E6%97%B6%E9%A3%8E%E6%8E%A7%E7%9A%84%E5%BA%94%E7%94%A8.assets/640-164499913260517-164499913391419.webp)

- 上图展示了一个例子，在kaggle上一个房屋保险的数据集，标签就是用户在保险支付阶段会不会取消，可以看到我们右边有两个叫做Tabnet的一个deep learning的模型，它又是优化模型，又在训练技巧上尝试**预训练**来加强自己的特征表现，时间上数百倍的增加，但其实在效果上跟MLP在我们从业务层面来看是差不多的。

- 因为**在数值特征，分支选取上GBDT这些模型要更高效一些**，哪怕是离散特征，其实GBDT模型各自实现的库也是有比较高效的自适应的编码的能力的。而且datascientist已经在*特征工程方面把一跳的连接关系*的一些特征给考虑在内了，也就是说哪怕用传统模型，结合图片量也能达到提高性能的目的。所以我们下面直接要跟GBDT模型去做对比，必须要**有很高的提升才考虑部署这么一个耗费巨大的方案**。

## 3. 端到端方案

### 3.1 有向动态切片图

- ![图片](eBay%20%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9C%A8%E5%AE%9E%E6%97%B6%E9%A3%8E%E6%8E%A7%E7%9A%84%E5%BA%94%E7%94%A8.assets/640-164499988817920-164499988989122.webp)
- 因为在实验阶段会横跨数个月去构建交易图，且涉及到公共IP和转运仓，公司地址这样的超级节点的存在，所以我们不得不对图进行切割，因为在eBay大部分的ETL都是使用Spark来做的，所以比较顺手的方案就是直接用cluster去做**切图**，做完切图以后就会得到上图中间显示的**静态二部图**。
- 构建有效动态图的切片图， 主要是由三种边来构成:
  - 一种就是(同一时间切片内)订单和关联实体的关联边
  - 第二种就是历史上关联实体，从比如说多少天前，映射到自己的有向传递边
  - 第三种就是**最近**有效的关联实体到这笔订单的边。这个边被特别标红了，也就是在==**生产阶段上被线上用到的**==，而其他的虚线边都是在离线情况下，完成了这些entity embedding的推断过程。
- 这三种边在端到端在学习的过程中都是会被用到的，只是在**==推断的时候被拆为了两部分==**，这样就保证了在对于交易风险评判的时候，只有少量的关联节点被获取到对应的构图。

### 3.2 Lambda架构的网络结构图

- ![图片](eBay%20%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9C%A8%E5%AE%9E%E6%97%B6%E9%A3%8E%E6%8E%A7%E7%9A%84%E5%BA%94%E7%94%A8.assets/640-164500034840123-164500035022625.webp)- 

- 可以看到左边蓝色的是关于**实体embedding推断**的层数堆叠，得到它的embedding以后，存到**Key-Value Database**里，然后等新的交易过来的时候，我们关联的entity直接是从Key-Value Database里面去获取，这样就**规避了图查询**这样的比较耗费时间的过程。

  然后在网络结构上，因为是基于切割后的小图进行的，在**分区切片图**上的学习形式会类似于ClusterGCN的形式，然后我们在构建GNN网络层的时候采用了类似**DeepGCN**的形式，包括残差的选项都加上了，这样的设计在实验训练中取得了较好的结果。

  最后把推断的最后一跳进行解耦，比较接近于在推荐系统里面常用的一个双塔模型，不过还需要最后经过一层MLP来得到结果，而不是一个cosine的形式，因为那边并不是一个简单的向量积的一个过程。

### 3.3 离线学习时的分区构图的形式 - 影子节点

- ![图片](eBay%20%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9C%A8%E5%AE%9E%E6%97%B6%E9%A3%8E%E6%8E%A7%E7%9A%84%E5%BA%94%E7%94%A8.assets/640-164500053178626-164500053297828.webp)
- ![图片](eBay%20%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9C%A8%E5%AE%9E%E6%97%B6%E9%A3%8E%E6%8E%A7%E7%9A%84%E5%BA%94%E7%94%A8.assets/640-164500055116829-164500055264331.webp)

- 影子节点： 其实order到entity的这样一个构边，我们引入了影子订单的形式。这样的好处就是能够加强交易点和关联实体的一个信息的传递的有效性，同时又能够隔绝未来信息的传入，不会影响到真实order risk的推断。
- 第一种边就是影子的交易节点和实体交易的双向边，**影子节点能够拿到同一个切片内的数据**，**但本身是不带标签的，不会参与交易风险的推断**；
- 第二种边的类型就是绿色表示的，历史entity到当下entity的边，我们会在窗口上设定一个时间限制比如说30天，也就是允许交易关联实体把30天之内有效的信息给传递过去；
- 第三个边交易实体，就是当交易发生时，前一个切片的交易实体到当下交易订单的一个传播，这也是线上真实使用到的传播路径。

### 3.4 编码有效性

- 对比GBDT，怎么能解决编码的有效性问题
- 类似于facebook在14年提出的GBDT加LR的架构： 首先是预训练一个GBDT，然后原始变量经过这个模型进行编码，保留叶子节点上的输出组成为向量以后**作为GNN模型的向量输入**。
- <img src="eBay%20%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9C%A8%E5%AE%9E%E6%97%B6%E9%A3%8E%E6%8E%A7%E7%9A%84%E5%BA%94%E7%94%A8.assets/640-164500084448332.webp" alt="图片" style="zoom: 67%;" />

##### **上线**的时候我们会有**两阶段的推断**

- 第一个就是**Entity-levelembedding的推断**，可能是每隔一小时或者是每隔一天通过**批处理**完成的，并存到Key-ValueDatabase里；
- <img src="eBay%20%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9C%A8%E5%AE%9E%E6%97%B6%E9%A3%8E%E6%8E%A7%E7%9A%84%E5%BA%94%E7%94%A8.assets/640-164500101129238.webp" alt="图片" style="zoom:67%;" />
- ==当order来的时候，首先就得到**order本身的原始变量**通过**GBDT编码后的特征表达**，以及在Key-Value Database查询得到**相关联的比如五六个节点的embedding**，（构成查询order的关联子图）输入**最后一层的GNN**再得到后面的**评估的分数**。==
- <img src="eBay%20%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9C%A8%E5%AE%9E%E6%97%B6%E9%A3%8E%E6%8E%A7%E7%9A%84%E5%BA%94%E7%94%A8.assets/640-164500099512335.webp" alt="图片" style="zoom:67%;" />

- （指模型部分内部）对应到线上的系统，就已经**不需要一个graphDB**了，而是直接**复用已有的基础设施**就能够把GNN的模型推上线，也就是**传统的变量仍然是通过传统的路径获得**，而**==最后一个时间片的实体的embedding信息其实就是一个local变量==**，它获取的成本会比之前我们接近数百个节点的特征变量的获取要轻便得多。
- ![图片](eBay%20%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9C%A8%E5%AE%9E%E6%97%B6%E9%A3%8E%E6%8E%A7%E7%9A%84%E5%BA%94%E7%94%A8.assets/640-164500122284541-164500122393743.webp)

### 3.5 实验结果

- 针对GNN实时图和LightGBM对比的一个实验的设定
  - <img src="eBay%20%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9C%A8%E5%AE%9E%E6%97%B6%E9%A3%8E%E6%8E%A7%E7%9A%84%E5%BA%94%E7%94%A8.assets/640-164500127634944.webp" alt="图片" style="zoom:67%;" />
  - 交易图是通过数个月的交易完成的，并*对构建节点数量加以限定*，也就是entity-level的*窗口*是要90天以内的，涉及到的关联实体包括账户，电子邮箱，设备收货地址和IP。
  - <img src="eBay%20%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9C%A8%E5%AE%9E%E6%97%B6%E9%A3%8E%E6%8E%A7%E7%9A%84%E5%BA%94%E7%94%A8.assets/640-164500132663547.webp" alt="图片" style="zoom:50%;" />
  - 堆叠的GNN里面比对了两种卷积层，一种就是GCN，一种是GAT，可以看到GCN的方法明显好于LightGBM，在平均准确率指标上有接近1/4的提升。但使用GAT并没有更好的表现，可能是因为调参的空间没有足够，后面也可以做更多的卷积层尝试，不过这里我们想要比较的并不是到底什么卷积层更厉害，而是想证明**引入时空图结构**确实能够**捕获到传统模型不能得到的特征表达**。将来也会在异构图上面尝试是不是能够有进一步的提升。

## 4. 小结和展望

- 端到端的图神经网络实时反欺诈检测的方案
  - 首先是**使用图切分**，让**分布式训练和推断**可行；
  - 然后是精心设计的，有效的**动态切片图**；
  - 最后在网络架构上也做了解耦，在**线上只用到一跳的查询**，使得线上的推断能够高效地完成。
- 将来需要进一步展开的一些方向
  - 对比**引入RNN的TGN**是不是在捕获能力上会有不一样的表现；
  - 现在并没有很好地展开的分区，一方面是由于要并行训练所以不得不做，另一方面就是看什么样的分区结构能对性能有不一样的影响，这也是有待进一步探索的。

## QA

Q：为什么要引入**影子订单**？

A：如果没有影子订单，我们作为**订单层就不方便去跟其他的实体订单产生太多的交互**，一旦产生太多交互，就有两种可能。一个是**容易引入未来信息，需要切片隔离**，而影子订单的存在是不会影响到真实order risk推断的 （**==???==**）；第二就是如果没有影子订单，但我还是要跟其他时间的订单有交互的话，就容易产生更加冗余的边，这个边是不是有效就值得探索了，而影子订单可以看到它和实体的边还是在同一个切片内的，这个切片可能是天级别的，比如说早上9点生成了一个订单，但是另外一个关联的实体可能是同一个电话号码在下午又发生了一个订单，影子订单是允许接收来自同一个时间切片的数据的，而带着label学习的真实订单是不允许有未来信息的，所以影子订单可以更好的作为信息传递的媒介，同时也隔绝了太多冗余边的摄入，否则在entity-level就只能跟自己交互了，不能通过order hub来进一步扩散传递过来的消息信息。