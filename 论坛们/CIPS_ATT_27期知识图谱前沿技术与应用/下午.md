## 因果启发的学习和推理

清华 崔鹏、沈哲言

-   AI is stepping into **risk-sensitive** areas
    -   互联网搜索推荐是风险不敏感的
    -   但是Fintech、AI-Law、Healthcare、Road&Driver Safety
    -   Shifting from **Performance Driven** to **Risk Sensitive**
-   **Explainability**
    -   Embedding-based methods for knowledge graoh acquisition are unexplainable
-   **Stability**
    -   Most ml methods are developed under I.I.D hyposthesis
    -   -> *OOD Generalisation* Problem

-   **Fairness**

-   **Verifiability** (可回溯性)

-   A plausible reason: **Correlation**

    -   correlation is the very basics of machine learning
    -   *(me: but yet correlation != causality)*
    -   **correlation is not explainable**
        -   其实只要是任意两个趋势变量， 那一定有相关性， 但其实可能完全没有关系！！

    -   **correlation is 'unstable'**
        -   区分correlation feature & causal features(从label的角度看)
        -   例如狗分类，图片背景都是correlation features， 狗本身才是causal features
        -    ==-> 如何让模型对correlation features insensitive？==

-   The way to use correlation:

    -   **Three sources of correlation**(类似BN中的D-seperation & explain away)
        -   Causation
            -   Causal mechanism
            -   **Stable & Explainable**
        -   Confounding： 混淆
            -   V-structure
            -   ignoreing X(root)
            -   Spurious Correlation 虚假关联
        -   Sample Selection Bias 样本选择性偏差
            -   Condition on S
            -   Spurious Correlation

    -   只有第一种correlation才是稳定可靠、可解释的

-   A Practical Defination of Causality
    -   类似于D-seperation/Conditional Indepence
    -   Causality into Learning
        -   思维实验
        -   因果框架下： Grass -> Strong Correlation & Weak Causation; 🐶 : Strong Correlation & Strong Causation
        -   More **Explainable** & Strong Causation

-   Explainability with Causality

    -   Causal And-Or Graph
    -   Counterfactual (Juerl 理论中的第三境界 What-if）
        -   在图像中则是，比如把一部分特征遮住或替换掉，如果预测标签发生变化则说明是causal features
    -   Causal Recommondation

-   Explainability & OOD

    -   Explainability & Stability 是同源的问题
    -   OOD <- Causality -> Explainability

    -   如何评价： Evaluation Metrics (公平性还有20+metrics， 但可解释性没有)， 则无法产生benchmark
        -   stability 可以通过多个OOD数据集测试进行评价 -> well-defined problem
    -   Explainability would be a side product when pursuing OOD with causality

-   Knowledge Graph and Causality

    -   Representation & Construction
        -   目前的实体：刻画了一种知识
        -   知识有两个层面
            -   知： Fact
            -   识： Causality (背后的逻辑)
    -   Inference
    -   Utility:
        -   Prediction
        -   Inference 
        -   Decision

-   Paradigms

    -   Structural Causal Model -- Book of why 作者的体系
    -   Causal Identification 
    -   Causal Estimation 
    -   框架可解决： 已知causal结构之后的推理、决策
    -   **How to discover the causal structure?**
    -   **Causal Discovery**
        -   Conditional Independence Testing -> 推出DAG
        -   问题： 组合爆炸
        -   天然问题： 高维高噪声， open question: 如何将causal model与learning model结合
        -   一条可能的路径: Differentiable Causal Model
    -   Potential Outcome Framework(Robin的路径)
        -   问题设定更简单， 像**控制变量法**
        -   但stronger assumption：所有混淆变量(confounders) are observed， 如果没有则需要approximation
        -   更像一个discriminative的方式
        -   计算更友好，设定上与prediction problem更近
        -   Causal Effect Estimation
            -   ATE
            -   **Conterfactual Problem**
                -   现实： 不可能同时观测到一个时间的两个结果(例如一个人吃药和不吃药的结果不可能都观测到) -> 无法控制X
                -   Ideal World: Conterfactual World
                -   实际：随机对照实验Randomized Experiments： Golden Standard
                    -   **核心： 平衡X在不同group里的分布** (i.e.完全随机保证X无偏)
                    -   问题：要求足够多的被试、人道主义问题(例如吸烟导致肺炎)
                -   Observational Studies
                    -   自然的分化X一定有偏差(例如是否进ICU)
                    -   方法： **Matching** -> find matching pairs
                        -   ==类似Active Learning？==
                        -   问题： X实际大概率是高维的 -> 高维诅咒
                    -   **Propensity Score**:
                        -   将高维向量转化为标量： 一个score
                        -   ==怎么转？？==
                        -   问题： 仍然是一个hard solution, 会有match不上的样本被扔掉
                    -   **IPW**：
                        -   matching 进化为 **sample reweighting**
                        -   对样本进行重加权
                        -   求期望ATE
                    -   **Non-parametric Solution**
                        -   Directly Confounder Balancing
                            -   直接学样本权重
                            -   问题： 如何**刻画X的分布** -> **moments**
                        -   Entropy Balancing
                            -   使weight 的entropy尽量小， 减小抖动

-   Gap btw Causality & Learning

-   **Stability learning** & its development

    -   I.I.D Learning
    -   Transfer Learning
    -   这两种问题都有假设： ***已知***testing distribution

    -   ML中： 无法控制对照组的形成，都是观测性数据
    -   传统causal inference是一个单变量对单变量的影响， 但prediction是多对一的
    -   **Global Balancing**
        -   理论证明： 存在一组最优的weights使得样本独立（i.e.所有confounders都平衡）
    -   **Causal Regularizer** for Global Balancing
        -   ==moment & sample reweight（使得各维独立？？==） 
        -   e.g. CRLR: **如何从correlation model变成causal model**
    -   Limitations of Global Balancing
        -   assumption： overlap
    -   From Shallow to Deep - DGBR
        -   Deep AE ： 目的: 降维 (解决overlap假设)
        -   真实世界中cofounder可能是有关的
    -   From Binary to Continous Variable - DWR

-   2条路径： 更直接的logic， 跳过casual variables

-   Non-Linear Causal

    -   StableNet
        -   与ResNet相比， 加了一条RFF 旁路用于 Sample Reweighting
    -   RFF feature map

-   OOD generalization: Model vs Optimization

    -   ERM

-   ERM -> HRM

-   Kernel HRM

